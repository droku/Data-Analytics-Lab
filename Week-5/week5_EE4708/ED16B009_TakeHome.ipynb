{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMWp3bQP-bhU"
   },
   "source": [
    "# Lab 5 - Classification : Naive Bayes and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n-5YUdzFsqwL"
   },
   "source": [
    "# Optical recognition of handwritten digits dataset\n",
    "**Download dataset from sklearn. The dataset has 10 classes and 64 attributes (8x8 images). Visualise images from the dataset. Perform a train test split in the ratio 4:1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6w_FSrzBE5pw"
   },
   "source": [
    "# Using sklearn (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ANyyLqRaE-RA"
   },
   "source": [
    "**For this exercise, you will use the naive bayes and logistic regression functions in sklearn. Use the optical recognition dataset.**\n",
    "\n",
    "\n",
    "**a) Logistic Regression - use one vs all classification method to classify the dataset into one of the ten classes. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too). Tune parameters to obtain the best results.**\n",
    "\n",
    "**b) Naive Bayes - perform multiclass classification to classify the dataset into one of the ten classes. Experiment with all the priors available (Gaussian, Bernoulli, etc) and report the best prior. Report the accuracies in terms of F1 scores and the confusion matrix (use sklearn functions for this too).**\n",
    "\n",
    "**Estimated Time: 50 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvL8quVdN24q"
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f1e376ba90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(digits.images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_metrics(ypred, ytrue):\n",
    "    print('accuracy: ',accuracy_score(ypred, ytrue))\n",
    "    print('f1 scores for each class: ',f1_score(ytrue, ypred, average = None))\n",
    "    print('confusion matrix: ')\n",
    "    print(confusion_matrix(ytrue, ypred))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.logspace(-3,3,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:28<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for alpha_val in tqdm(alpha):\n",
    "    logR = LogisticRegression(C = alpha_val)\n",
    "    logR.fit(xtrain, ytrain)\n",
    "    predictions = logR.predict(xtest)\n",
    "    #predict_metrics(predictions, ytest)\n",
    "    accuracy = accuracy_score(predictions, ytest)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_alpha = alpha_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694444444444444\n",
      "1.7030650292528444\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)\n",
    "print(best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9694444444444444\n",
      "f1 scores for each class:  [1.         0.94252874 0.98591549 0.98795181 0.96202532 1.\n",
      " 0.97368421 0.98360656 0.93333333 0.93670886]\n",
      "confusion matrix: \n",
      "[[34  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 41  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 35  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 41  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 38  0  0  1  0  2]\n",
      " [ 0  0  0  0  0 28  0  0  0  0]\n",
      " [ 0  2  0  0  0  0 37  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  2  1  0  0  0  0  0 28  0]\n",
      " [ 0  1  0  0  0  0  0  0  1 37]]\n"
     ]
    }
   ],
   "source": [
    "best_model = LogisticRegression(C = best_alpha)\n",
    "best_model.fit(xtrain, ytrain)\n",
    "predictions = best_model.predict(xtest)\n",
    "predict_metrics(predictions, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8111111111111111\n",
      "f1 scores for each class:  [1.         0.76315789 0.61818182 0.87804878 0.7761194  0.96296296\n",
      " 0.975      0.6741573  0.69230769 0.78873239]\n",
      "confusion matrix: \n",
      "[[34  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 29  1  0  0  0  1  6  3  1]\n",
      " [ 0  1 17  3  0  0  0  0 13  1]\n",
      " [ 0  0  1 36  0  0  0  0  3  2]\n",
      " [ 0  1  0  0 26  0  0 14  0  0]\n",
      " [ 0  0  0  0  0 26  0  2  0  0]\n",
      " [ 0  0  0  0  0  0 39  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 30  0  0]\n",
      " [ 0  2  0  0  0  0  0  2 27  0]\n",
      " [ 0  2  1  1  0  0  1  5  1 28]]\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(xtrain, ytrain)\n",
    "predictions = gnb.predict(xtest)\n",
    "predict_metrics(predictions, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8694444444444445\n",
      "f1 scores for each class:  [0.98507463 0.775      0.83333333 0.92307692 0.91139241 0.85714286\n",
      " 0.96103896 0.87878788 0.75362319 0.81927711]\n",
      "confusion matrix: \n",
      "[[33  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 31  5  0  0  0  1  0  3  1]\n",
      " [ 0  1 30  0  0  0  0  1  3  0]\n",
      " [ 0  0  1 36  0  0  0  0  2  3]\n",
      " [ 0  1  0  0 36  0  0  2  2  0]\n",
      " [ 0  0  0  0  1 21  0  0  0  6]\n",
      " [ 0  2  0  0  0  0 37  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 29  1  0]\n",
      " [ 0  3  1  0  0  0  0  1 26  0]\n",
      " [ 0  1  0  0  0  0  0  3  1 34]]\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain, ytrain)\n",
    "predictions = mnb.predict(xtest)\n",
    "predict_metrics(predictions, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8\n",
      "f1 scores for each class:  [0.95522388 0.52631579 0.7826087  0.88607595 0.86419753 0.75555556\n",
      " 0.925      0.85294118 0.67605634 0.76190476]\n",
      "confusion matrix: \n",
      "[[32  0  0  0  2  0  0  0  0  0]\n",
      " [ 0 20  6  0  2  0  1  1 10  1]\n",
      " [ 0  1 27  2  0  0  0  1  4  0]\n",
      " [ 0  1  1 35  0  0  0  0  1  4]\n",
      " [ 0  1  0  0 35  0  1  4  0  0]\n",
      " [ 1  2  0  0  1 17  2  0  0  5]\n",
      " [ 0  2  0  0  0  0 37  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 29  1  0]\n",
      " [ 0  3  0  0  0  0  0  1 24  3]\n",
      " [ 0  5  0  0  0  0  0  2  0 32]]\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(xtrain, ytrain)\n",
    "predictions = bnb.predict(xtest)\n",
    "predict_metrics(predictions, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistics regression has high accuracy and f1 score compared to naive bayes.\n",
    "- The best parameter for C = 1.703.\n",
    "- Multinomial Naive bayes perform better in comparison with other gaussian and bernoulli nb.\n",
    "- Naive bayes fails to capture the dependence in the features of the numbers which leads to lower accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oli7OP9XN4ZF"
   },
   "source": [
    "Summarize your findings and results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aiq6KaGLOAba"
   },
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab5_DataAnalytics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
